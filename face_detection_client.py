import cv2
import numpy as np
import requests
import argparse
import sys
from threading import Thread
import time
import urllib3

# Táº¯t warning SSL cho dev tunnels
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class VideoStreamDetector:
    """
    Class xá»­ lÃ½ video stream vÃ  face detection
    """
    def __init__(self, stream_url, window_name="Face Detection"):
        self.stream_url = stream_url
        self.window_name = window_name
        self.stopped = False
        self.frame = None
        self.grabbed = False
        
        # Load Haar Cascade cho face detection
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        
        # Thá»‘ng kÃª
        self.fps = 0
        self.frame_count = 0
        self.start_time = time.time()
        
    def start(self):
        """Báº¯t Ä‘áº§u thread Ä‘á»c stream"""
        Thread(target=self.update, args=(), daemon=True).start()
        return self
    
    def update(self):
        """Thread liÃªn tá»¥c Ä‘á»c frame tá»« stream"""
        try:
            print(f"ğŸ”— Äang káº¿t ná»‘i tá»›i: {self.stream_url}")
            
            # Headers Ä‘á»ƒ giáº£ láº­p browser vÃ  bypass ngrok warning
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'multipart/x-mixed-replace,*/*',
                'ngrok-skip-browser-warning': 'true'  # Bypass ngrok warning page
            }
            
            # Káº¿t ná»‘i tá»›i stream vá»›i timeout dÃ i hÆ¡n cho HTTPS
            stream = requests.get(
                self.stream_url, 
                stream=True, 
                timeout=30,
                headers=headers,
                verify=False  # Bá» qua SSL verification cho dev tunnels
            )
            
            if stream.status_code != 200:
                print(f"âŒ Lá»—i káº¿t ná»‘i: HTTP {stream.status_code}")
                self.stopped = True
                return
            
            # Kiá»ƒm tra Content-Type
            content_type = stream.headers.get('Content-Type', '')
            if 'html' in content_type.lower():
                print(f"âŒ Lá»—i: Server tráº£ vá» HTML thay vÃ¬ video stream!")
                print(f"   Content-Type: {content_type}")
                print(f"\nğŸ’¡ CÃ³ thá»ƒ do:")
                print(f"   - Dev Tunnel yÃªu cáº§u authentication")
                print(f"   - URL khÃ´ng Ä‘Ãºng")
                print(f"   - Server khÃ´ng cháº¡y")
                print(f"\nğŸ“– Xem hÆ°á»›ng dáº«n: PUBLIC_STREAMING_GUIDE.md")
                self.stopped = True
                return
            
            print("âœ“ Káº¿t ná»‘i thÃ nh cÃ´ng!")
            print(f"   Content-Type: {content_type}")
            
            bytes_data = bytes()
            first_frame_received = False
            no_jpeg_count = 0
            max_no_jpeg = 100  # Dá»«ng sau 100 chunk khÃ´ng cÃ³ JPEG
            
            for chunk in stream.iter_content(chunk_size=8192):  # TÄƒng buffer size
                if self.stopped:
                    break
                
                bytes_data += chunk
                
                # TÃ¬m JPEG boundary
                a = bytes_data.find(b'\xff\xd8')  # JPEG start
                b = bytes_data.find(b'\xff\xd9')  # JPEG end
                
                if a != -1 and b != -1:
                    jpg = bytes_data[a:b+2]
                    bytes_data = bytes_data[b+2:]
                    
                    # Reset counter
                    no_jpeg_count = 0
                    
                    # Decode frame
                    frame = cv2.imdecode(
                        np.frombuffer(jpg, dtype=np.uint8), 
                        cv2.IMREAD_COLOR
                    )
                    
                    if frame is not None:
                        self.frame = frame
                        self.grabbed = True
                        self.frame_count += 1
                        
                        if not first_frame_received:
                            first_frame_received = True
                            print(f"âœ“ ÄÃ£ nháº­n frame Ä‘áº§u tiÃªn! KÃ­ch thÆ°á»›c: {frame.shape}")
                else:
                    # KhÃ´ng tÃ¬m tháº¥y JPEG trong chunk nÃ y
                    no_jpeg_count += 1
                    if no_jpeg_count >= max_no_jpeg and not first_frame_received:
                        print(f"âŒ KhÃ´ng nháº­n Ä‘Æ°á»£c JPEG data sau {max_no_jpeg} chunks!")
                        print(f"   Stream cÃ³ thá»ƒ khÃ´ng pháº£i lÃ  video stream.")
                        print(f"   Thá»­ debug: python debug_stream.py {self.stream_url}")
                        self.stopped = True
                        break
        
        except requests.exceptions.RequestException as e:
            print(f"âŒ Lá»—i káº¿t ná»‘i: {e}")
            self.stopped = True
        except Exception as e:
            print(f"âŒ Lá»—i: {e}")
            import traceback
            traceback.print_exc()
            self.stopped = True
    
    def read(self):
        """Äá»c frame hiá»‡n táº¡i"""
        return self.grabbed, self.frame
    
    def stop(self):
        """Dá»«ng stream"""
        self.stopped = True
    
    def detect_faces(self, frame):
        """
        PhÃ¡t hiá»‡n khuÃ´n máº·t trong frame
        
        Returns:
            frame: Frame Ä‘Ã£ Ä‘Æ°á»£c váº½ box
            faces: Danh sÃ¡ch tá»a Ä‘á»™ khuÃ´n máº·t
        """
        # Chuyá»ƒn sang grayscale Ä‘á»ƒ detect
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Detect faces
        faces = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(30, 30),
            flags=cv2.CASCADE_SCALE_IMAGE
        )
        
        # Váº½ box cho má»—i khuÃ´n máº·t
        for (x, y, w, h) in faces:
            # Váº½ hÃ¬nh chá»¯ nháº­t mÃ u xanh lÃ¡
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            
            # ThÃªm text "Face"
            cv2.putText(
                frame, 
                'Face', 
                (x, y-10),
                cv2.FONT_HERSHEY_SIMPLEX, 
                0.7, 
                (0, 255, 0), 
                2
            )
            
            # Váº½ Ä‘iá»ƒm tÃ¢m
            center_x = x + w // 2
            center_y = y + h // 2
            cv2.circle(frame, (center_x, center_y), 3, (0, 0, 255), -1)
        
        return frame, faces
    
    def add_info_overlay(self, frame, faces):
        """ThÃªm thÃ´ng tin lÃªn frame"""
        height, width = frame.shape[:2]
        
        # TÃ­nh FPS
        elapsed_time = time.time() - self.start_time
        if elapsed_time > 0:
            self.fps = self.frame_count / elapsed_time
        
        # Background cho text (semi-transparent)
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (width, 100), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
        
        # ThÃ´ng tin
        info_texts = [
            f"Faces Detected: {len(faces)}",
            f"FPS: {self.fps:.1f}",
            f"Stream: {self.stream_url[:50]}..."
        ]
        
        y_offset = 25
        for i, text in enumerate(info_texts):
            if i == 0:
                color = (0, 255, 0) if len(faces) > 0 else (255, 255, 255)
            else:
                color = (255, 255, 255)
            
            cv2.putText(
                frame, 
                text, 
                (10, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX, 
                0.6, 
                color, 
                2
            )
            y_offset += 25
        
        # HÆ°á»›ng dáº«n
        help_text = "Press 'q' or 'ESC' to quit | 's' to save screenshot"
        cv2.putText(
            frame,
            help_text,
            (10, height - 10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (255, 255, 255),
            1
        )
        
        return frame
    
    def run(self):
        """Cháº¡y chÆ°Æ¡ng trÃ¬nh chÃ­nh"""
        print("=" * 70)
        print("ğŸ¯ FACE DETECTION FROM VIDEO STREAM")
        print("=" * 70)
        print()
        
        # Báº¯t Ä‘áº§u stream
        self.start()
        
        # Äá»£i frame Ä‘áº§u tiÃªn (tÄƒng thá»i gian Ä‘á»£i cho HTTPS)
        print("â³ Äang Ä‘á»£i frame Ä‘áº§u tiÃªn...")
        print("   (CÃ³ thá»ƒ máº¥t vÃ i giÃ¢y vá»›i HTTPS/dev tunnels...)")
        wait_count = 0
        max_wait = 150  # TÄƒng tá»« 50 lÃªn 150 (15 giÃ¢y)
        
        while not self.grabbed and not self.stopped and wait_count < max_wait:
            time.sleep(0.1)
            wait_count += 1
            
            # Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh
            if wait_count % 10 == 0:
                print(f"   Äang Ä‘á»£i... ({wait_count//10}s)")
        
        if self.stopped or not self.grabbed:
            print("âŒ KhÃ´ng thá»ƒ láº¥y frame tá»« stream!")
            print("ğŸ’¡ Gá»£i Ã½:")
            print("   - Kiá»ƒm tra URL cÃ³ Ä‘Ãºng khÃ´ng")
            print("   - Thá»­ má»Ÿ URL trong browser xem cÃ³ stream khÃ´ng")
            print("   - Kiá»ƒm tra káº¿t ná»‘i máº¡ng")
            print("   - Server cÃ³ thá»ƒ Ä‘ang báº­n, thá»­ láº¡i sau")
            return
        
        print("âœ“ ÄÃ£ nháº­n frame Ä‘áº§u tiÃªn!")
        print()
        print("ğŸ“¹ Äang hiá»ƒn thá»‹ video vá»›i face detection...")
        print("   - Nháº¥n 'q' hoáº·c 'ESC' Ä‘á»ƒ thoÃ¡t")
        print("   - Nháº¥n 's' Ä‘á»ƒ chá»¥p áº£nh mÃ n hÃ¬nh")
        print()
        
        screenshot_count = 0
        
        # VÃ²ng láº·p chÃ­nh
        try:
            while not self.stopped:
                grabbed, frame = self.read()
                
                if not grabbed or frame is None:
                    time.sleep(0.01)
                    continue
                
                # Detect faces
                processed_frame, faces = self.detect_faces(frame.copy())
                
                # ThÃªm overlay info
                processed_frame = self.add_info_overlay(processed_frame, faces)
                
                # Hiá»ƒn thá»‹
                cv2.imshow(self.window_name, processed_frame)
                
                # Xá»­ lÃ½ phÃ­m
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q') or key == 27:  # 'q' hoáº·c ESC
                    print("\nâ¹ï¸  Äang dá»«ng...")
                    break
                elif key == ord('s'):  # 's' Ä‘á»ƒ save screenshot
                    screenshot_count += 1
                    filename = f"screenshot_{screenshot_count}_{int(time.time())}.jpg"
                    cv2.imwrite(filename, processed_frame)
                    print(f"ğŸ“¸ ÄÃ£ lÆ°u: {filename}")
        
        except KeyboardInterrupt:
            print("\nâš ï¸  ÄÃ£ dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng")
        except Exception as e:
            print(f"\nâŒ Lá»—i: {e}")
        finally:
            # Cleanup
            self.stop()
            cv2.destroyAllWindows()
            
            print()
            print("ğŸ“Š Thá»‘ng kÃª:")
            print(f"   - Tá»•ng frames: {self.frame_count}")
            print(f"   - FPS trung bÃ¬nh: {self.fps:.2f}")
            print(f"   - Thá»i gian cháº¡y: {time.time() - self.start_time:.1f}s")
            print()
            print("âœ“ ChÆ°Æ¡ng trÃ¬nh Ä‘Ã£ káº¿t thÃºc")


def main():
    """HÃ m main"""
    parser = argparse.ArgumentParser(
        description='Face Detection tá»« Video Stream',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
VÃ­ dá»¥ sá»­ dá»¥ng:
  # Stream tá»« local server
  python face_detection_client.py http://localhost:5000/video_feed/0
  
  # Stream tá»« IP camera
  python face_detection_client.py http://192.168.1.100:8080/video
  
  # Stream vá»›i tÃªn cá»­a sá»• tÃ¹y chá»‰nh
  python face_detection_client.py http://localhost:5000/video_feed/1 -w "My Camera"
        """
    )
    
    parser.add_argument(
        'stream_url',
        nargs='?',
        default='http://localhost:5000/video_feed/0',
        help='URL cá»§a video stream (máº·c Ä‘á»‹nh: http://localhost:5000/video_feed/0)'
    )
    
    parser.add_argument(
        '-w', '--window',
        default='Face Detection',
        help='TÃªn cá»­a sá»• hiá»ƒn thá»‹ (máº·c Ä‘á»‹nh: Face Detection)'
    )
    
    args = parser.parse_args()
    
    # Kiá»ƒm tra URL
    if not args.stream_url.startswith(('http://', 'https://', 'rtsp://')):
        print("âŒ URL khÃ´ng há»£p lá»‡! Pháº£i báº¯t Ä‘áº§u vá»›i http://, https:// hoáº·c rtsp://")
        sys.exit(1)
    
    # Khá»Ÿi táº¡o vÃ  cháº¡y detector
    detector = VideoStreamDetector(args.stream_url, args.window)
    detector.run()


if __name__ == '__main__':
    main()
